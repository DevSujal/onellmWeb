# OneLLM Spring Boot Configuration

# Server
server.port=${PORT:8080}
server.servlet.context-path=/

# Application
spring.application.name=onellm

# Logging - set to DEBUG for streaming troubleshooting
logging.level.io.onellm=DEBUG

# ======= LLM Provider Configuration =======
# Set API keys via environment variables or directly here
# Environment variable format: ONELLM_OPENAI_API_KEY, ONELLM_ANTHROPIC_API_KEY, etc.

# OpenAI
onellm.openai.api-key=${ONELLM_OPENAI_API_KEY:}
onellm.openai.base-url=https://api.openai.com/v1

# Anthropic
onellm.anthropic.api-key=${ONELLM_ANTHROPIC_API_KEY:}

# Google Gemini
onellm.google.api-key=${ONELLM_GOOGLE_API_KEY:}

# Azure OpenAI
onellm.azure.api-key=${ONELLM_AZURE_API_KEY:}
onellm.azure.resource-name=${ONELLM_AZURE_RESOURCE_NAME:}
onellm.azure.deployment-name=${ONELLM_AZURE_DEPLOYMENT_NAME:}

# Groq
onellm.groq.api-key=${ONELLM_GROQ_API_KEY:}

# Cerebras
onellm.cerebras.api-key=${ONELLM_CEREBRAS_API_KEY:}

# Ollama (local, enabled by default)
onellm.ollama.enabled=true
onellm.ollama.base-url=http://localhost:11434

# OpenRouter
onellm.openrouter.api-key=${ONELLM_OPENROUTER_API_KEY:}
onellm.openrouter.site-name=OneLLM
onellm.openrouter.site-url=https://github.com/onellm

# xAI
onellm.xai.api-key=${ONELLM_XAI_API_KEY:}

# Copilot
onellm.copilot.api-key=${ONELLM_COPILOT_API_KEY:}
